# ZhouChengShuai-DataMining

## 创建一个仓库
在Home页左上角点击New，命名为ZhouChengShuai-DataMining，并勾选Add a READNE file

## 上传ppt
### 方法一
1、在创建好的仓库中，点击Add file --> Upload files

2、将自己的PPT拖入到文件框中，或者点击chosse your files选择自己的PPT

3、点击左下角的Commit changes按钮，即可上传成功

### 方法二
1、在本地创建一个文件夹

2、在新建的仓库点击Code --> Copy url to clipboard 复制地址

3、执行 git clone 操作，将创建的仓库克隆到本地

`git clone https://github.com/ZCSLHN/ZhouChengShuai-DataMining.git`

4、打开终端，使用 git add 命令将文件添加到暂存区

`git add 多智能体强化学习 (1).pptx`

5、使用 git commit 命令将更改提交到本地仓库

`git commit -m "Add 多智能体强化学习 (1).pptx"`

6、将更改推送到远程仓库

`git push origin main`

## 相关技能学习
多智能体强化学习（MARL）是人工智能的一个分支，它涉及多个智能体在共享的环境中通过交互学习最优行为策略，以最大化累积奖励。每个智能体根据自身的策略和环境反馈（奖励信号）进行决策，同时必须考虑到其他智能体的策略和潜在的合作或竞争关系。MARL的目标是找到一组策略，这些策略能够使所有智能体在多智能体系统中高效协作或竞争，以解决复杂任务。MARL已被应用于多个领域，包括机器人系统、分布式决策、交通控制、商业管理等。它在自动驾驶、能源管理、编队控制、航迹规划、路由规划、社会难题等现实领域有广泛应用。

### 相关知识
1、学习如何合理的设计奖励函数：奖励函数的设计在多智能体强化学习中至关重要，因为它直接影响智能体的行为策略、学习过程和最终的系统性能。

2、学习如何平衡探索和利用：在多智能体强化学习（MARL）中，探索（Exploration）与利用（Exploitation）的平衡是确保智能体有效学习并达到最优策略的关键因素。

3、学习如何合理的处理多智能体之间的合作与竞争关系：现实中大部分的场景的多智能体之间既有合作又有竞争，它们对智能体的策略选择、学习过程和系统性能有着根本性的影响。

4、对于智能体之间的合作，学习如何有效的设计有效的通信机制。

5、了解如何使用并行计算和分布式系统来加速多智能体强化学习算法。

6、学习如何处理策略空间的维度灾难问题：随着智能体数量的增加，整个系统的策略空间呈指数增长，这可能导致计算和搜索空间变得非常庞大。
